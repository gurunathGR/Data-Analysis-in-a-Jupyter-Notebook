{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906158d3-6a76-44ba-a978-9eb839ad87b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import sys\n",
    "import re\n",
    "'''Initial ingestion of data and then counting the total number of instances in the whole data set'''\n",
    "def data_process(input):\n",
    " with open(input) as file:\n",
    " files = file.readlines()\n",
    " no_of_instances, no_of_instances2, no_of_empty_lines, ii = 0, 0, 0, 0\n",
    " line_contents, line_contents2, sector_contents, list_of_line_contents = list(), list(), list(),\n",
    "list()\n",
    " for line in files:\n",
    " no_of_instances += 1\n",
    " if len(line) <= 1:\n",
    " no_of_empty_lines += 1\n",
    " line_contents.append(line.split())\n",
    " for i in line_contents:\n",
    " if len(i) == 0:\n",
    " ii += 1\n",
    " line_contents.remove(i)\n",
    " sector_contents.append(list_of_line_contents)\n",
    " list_of_line_contents = []\n",
    " else:\n",
    " no_of_instances2 += 1\n",
    " line_contents2.append(i)\n",
    " list_of_line_contents.append(i)\n",
    " No_of_Instances_in_Original_File = len(sector_contents)\n",
    " return sector_contents, No_of_Instances_in_Original_File\n",
    "'''Filtering out the unwanted items in an instance and count the initial count of each sense\n",
    "type'''\n",
    "def data_segment(list_of_features):\n",
    " for i in range(len(list_of_features)):\n",
    " if len(list_of_features[i]) == 5:\n",
    " list_of_features[i].remove(['<context>'])\n",
    " list_of_features[i].remove(['</context>'])\n",
    " list_of_features[i].remove(['</instance>'])\n",
    " elif len(list_of_features[i]) == 6:\n",
    " list_of_features[i].pop(0)\n",
    " list_of_features[i].remove(['</instance>'])\n",
    " list_of_features[i].remove(['<context>'])\n",
    " list_of_features[i].remove(['</context>'])\n",
    " Initial_label_Dict = dict()\n",
    " ''' Count of number of instances for each class in the original data set'''\n",
    " Prob_sense_dict = dict()\n",
    " for i in range(len(list_of_features)):\n",
    " item = list_of_features[i][0][2].split('=')[-1].split('%')[-1].strip('\"/>')\n",
    " if item in Initial_label_Dict.keys():\n",
    " Initial_label_Dict[item] = Initial_label_Dict[item] + 1\n",
    " elif item not in Initial_label_Dict.keys():\n",
    " Initial_label_Dict[item] = 1\n",
    " for item in Initial_label_Dict.keys():\n",
    " Prob_sense_dict[item] = Initial_label_Dict[item] / sum(Initial_label_Dict.values())\n",
    " list_of_features_with_label1 = []\n",
    " list_of_features_with_label2 = []\n",
    " label_feature_dict = dict()\n",
    " for i in range(len(list_of_features)):\n",
    " item = list_of_features[i][0][2].split('=')[-1].split('%')[-1].strip('\"/>')\n",
    " for j in Initial_label_Dict.keys():\n",
    " if item == j and (item == 'factory' or item == 'fish' or item == 'machine' or item ==\n",
    "'physical' or item == 'hand' or item == 'container'):\n",
    " list_of_features_with_label1.append(list_of_features[i][1])\n",
    " label_feature_dict[item] = list_of_features_with_label1\n",
    " elif item == 'living' or item == 'music' or item == 'bird' or item == 'legal' or item == 'tree'\n",
    "or item == 'vehicle':\n",
    " list_of_features_with_label2.append(list_of_features[i][1])\n",
    " label_feature_dict[item] = list_of_features_with_label2\n",
    " ''' Copy similar for other data sets'''\n",
    " # print(list_of_features)\n",
    " complete_feature_list = dict()\n",
    " complete_feature_list_for_label1 = dict()\n",
    " complete_feature_list_for_label2 = dict()\n",
    " ''' Dictionary of all words in the complete data set'''\n",
    " for i in range(len(list_of_features)):\n",
    " for j in range(len(list_of_features[i][1])):\n",
    " word = re.sub(r'[^-\\w]', '', list_of_features[i][1][j])\n",
    " # print(word)\n",
    " if word in complete_feature_list.keys():\n",
    " complete_feature_list[word] = complete_feature_list[word] + 1\n",
    " elif word not in complete_feature_list.keys():\n",
    " complete_feature_list[word] = 1\n",
    " # print(len(complete_feature_list))\n",
    " ''' Dictionary of all the features for sense 1'''\n",
    " for i in range(len(list_of_features_with_label1)):\n",
    " for j in range(len(list_of_features_with_label1[i])):\n",
    " word = re.sub(r'[^-\\w]', '', list_of_features_with_label1[i][j])\n",
    " if word not in complete_feature_list_for_label1.keys():\n",
    " complete_feature_list_for_label1[word] = 1\n",
    " elif word in complete_feature_list_for_label1.keys():\n",
    " complete_feature_list_for_label1[word] = complete_feature_list_for_label1[word] + 1\n",
    " # print(len(complete_feature_list_for_label1))\n",
    " ''' Dictionary of all the features for sense 2'''\n",
    " for i in range(len(list_of_features_with_label2)):\n",
    " for j in range(len(list_of_features_with_label2[i])):\n",
    " word = re.sub(r'[^-\\w]', '', list_of_features_with_label2[i][j])\n",
    " if word not in complete_feature_list_for_label2.keys():\n",
    " complete_feature_list_for_label2[word] = 1\n",
    " elif word in complete_feature_list_for_label2.keys():\n",
    " complete_feature_list_for_label2[word] = complete_feature_list_for_label2[word] + 1\n",
    " # print(len(complete_feature_list_for_label2))\n",
    " return list_of_features, complete_feature_list, complete_feature_list_for_label1,\n",
    "complete_feature_list_for_label2, Initial_label_Dict, Prob_sense_dict\n",
    "def cross_fold_creation(list_of_features):\n",
    " extra = len(list_of_features) % 5\n",
    " fold1, fold2, fold3, fold4, fold5 = [], [], [], [], []\n",
    " new_length = 0\n",
    " if extra != 0:\n",
    " new_length = len(list_of_features) + (5 - extra)\n",
    " else:\n",
    " new_length = len(list_of_features)\n",
    " fold_lenght = int(new_length / 5)\n",
    " # print(fold_length)\n",
    " fold1 = list_of_features[0:fold_lenght]\n",
    " fold2 = list_of_features[fold_lenght: 2 * fold_lenght]\n",
    " fold3 = list_of_features[2 * fold_lenght: 3 * fold_lenght]\n",
    " fold4 = list_of_features[3 * fold_lenght: 4 * fold_lenght]\n",
    " fold5 = list_of_features[4 * fold_lenght:]\n",
    " # print(len(fold1), len(fold2), len(fold3), len(fold4), len(fold5))\n",
    " return fold1, fold2, fold3, fold4, fold5\n",
    "def creating_train_test_segments(fold1, fold2, fold3, fold4, fold5):\n",
    " list_of_folds = [fold1, fold2, fold3, fold4, fold5]\n",
    " list_of_train_sets = []\n",
    " list_of_test_sets = []\n",
    " ''' Adding the list of test folds to a list of all test folds'''\n",
    " for i in range(5):\n",
    " list_of_test_sets.append(list_of_folds[i])\n",
    " for i in range(5):\n",
    " list_of_intermediate_train_sets = []\n",
    " # print('Round number', i)\n",
    " for j in range(5):\n",
    " if list_of_test_sets[i] == list_of_folds[j]:\n",
    " # print('Fold ignored:', i)\n",
    " pass\n",
    " else:\n",
    " # print('Fold added:', j)\n",
    " list_of_intermediate_train_sets.append(list_of_folds[j])\n",
    " # print('------------------')\n",
    " # print(len(list_of_intermediate_train_sets[3]))\n",
    " list_of_train_sets.append(list_of_intermediate_train_sets)\n",
    " return list_of_train_sets, list_of_test_sets, list_of_folds\n",
    "def calculating_features_probabilities_for_each_set(list_of_train_sets, list_of_features, lenS1,\n",
    "lenS2, Initial_Sense_Dict, Prob_Sense_Dict):\n",
    " ''' Extracting Target word between the <head> and </head> tags, also listing all the features\n",
    "in all the train folds'''\n",
    " list_of_target_words_for_all_folds = list()\n",
    " list_of_features_for_all_folds = list()\n",
    " for i in range(len(list_of_train_sets)):\n",
    " list_of_target_words = list()\n",
    " list_of_features_for_each_fold = list()\n",
    " for j in range(len(list_of_train_sets[i])):\n",
    " for k in range(len(list_of_train_sets[i][j])):\n",
    " # print(list_of_train_sets[i][j][k][1])\n",
    " list_under_consideration = list_of_train_sets[i][j][k][1]\n",
    " for l in range(len(list_under_consideration)):\n",
    " if list_under_consideration[l].split('d>')[0] == '<hea':\n",
    " word = list_under_consideration[l].split('<head>')[-1].split('</head>')[0]\n",
    " list_of_target_words.append(word)\n",
    " else:\n",
    " list_of_features_for_each_fold.append(list_under_consideration[l])\n",
    " list_of_target_words_for_all_folds.append(list_of_target_words)\n",
    " list_of_features_for_all_folds.append(list_of_features_for_each_fold)\n",
    " # print(len(list_of_features_for_all_folds[4]))\n",
    " ''' Calculating V1, V2 for add one smoothing in each train set'''\n",
    " unique_sense1_word_count = []\n",
    " unique_sense2_word_count = []\n",
    " for i in range(len(list_of_train_sets)):\n",
    " Word_count = dict()\n",
    " Word_count2 = dict()\n",
    " for j in range(len(list_of_train_sets[i])):\n",
    " for k in range(len(list_of_train_sets[i][j])):\n",
    " sense = list_of_train_sets[i][j][k][0][-1].split('=\"')[-1].split('%')[-1].strip('\"/>')\n",
    " if sense == 'factory' or sense == 'fish' or sense == 'machine' or sense == 'physical' or\n",
    "sense == 'hand' or sense == 'container':\n",
    " for l in range(len(list_of_train_sets[i][j][k][1])):\n",
    " word = re.sub(r'[^-\\w]', '', list_of_train_sets[i][j][k][1][l])\n",
    " if word not in Word_count.keys():\n",
    " Word_count[word] = 1\n",
    " elif word in Word_count.keys():\n",
    " Word_count[word] = Word_count[word] + 1\n",
    " elif sense == 'living' or sense == 'music' or sense == 'bird' or sense == 'legal' or sense ==\n",
    "'tree' or sense == 'vehicle':\n",
    " for l in range(len((list_of_train_sets[i][j][k][1]))):\n",
    " word = re.sub(r'[^-\\w]', '', list_of_train_sets[i][j][k][1][l])\n",
    " if word not in Word_count2.keys():\n",
    " Word_count2[word] = 1\n",
    " elif sense in Word_count2.keys():\n",
    " Word_count2[word] = Word_count2[word] + 1\n",
    " unique_sense1_word_count.append(len(Word_count))\n",
    " unique_sense2_word_count.append(len(Word_count2))\n",
    " # print('qwertyuiop', unique_sense1_word_count)\n",
    " '''Dictionary containing count of each word in each sense and the counting the probabilities'''\n",
    " List_of_all_feature_count_dictionaries = list()\n",
    " for i in range(len(list_of_features_for_all_folds)):\n",
    " Dictionary_of_counts = dict()\n",
    " for j in range(len(list_of_features_for_all_folds[i])):\n",
    " word = re.sub(r'[^-\\w]', '', list_of_features_for_all_folds[i][j])\n",
    " if word in Dictionary_of_counts.keys():\n",
    " Dictionary_of_counts[word] = Dictionary_of_counts[word] + 1\n",
    " elif word not in Dictionary_of_counts.keys():\n",
    " Dictionary_of_counts[word] = 1\n",
    " List_of_all_feature_count_dictionaries.append(Dictionary_of_counts)\n",
    " # print('qwert',List_of_all_feature_count_dictionaries[0])\n",
    " ''' Create a list of features for different labels'''\n",
    " List_of_all_feature_count_for_sense1 = list()\n",
    " List_of_all_feature_count_for_sense2 = list()\n",
    " for i in range(len(list_of_train_sets)):\n",
    " List_of_fold_feature_count_for_sense1 = list()\n",
    " List_of_fold_feature_count_for_sense2 = list()\n",
    " for j in range(len(list_of_train_sets[i])):\n",
    " for k in range(len(list_of_train_sets[i][j])):\n",
    " sentence = list_of_train_sets[i][j][k][0]\n",
    " sense = sentence[-1].split('=\"')[-1].split('%')[-1].strip('\"/>')\n",
    " for l in range(len(list_of_train_sets[i][j][k][1])):\n",
    " word = re.sub(r'[^\\w-]', '', list_of_train_sets[i][j][k][1][l])\n",
    " if sense == 'living' or sense == 'music' or sense == 'bird' or sense == 'legal' or sense ==\n",
    "'tree' or sense == 'vehicle':\n",
    " List_of_fold_feature_count_for_sense2.append(word)\n",
    " elif sense == 'factory' or sense == 'fish' or sense == 'machine' or sense == 'physical' or\n",
    "sense == 'hand' or sense == 'container':\n",
    " List_of_fold_feature_count_for_sense1.append(word)\n",
    " List_of_all_feature_count_for_sense1.append(List_of_fold_feature_count_for_sense1)\n",
    " List_of_all_feature_count_for_sense2.append(List_of_fold_feature_count_for_sense2)\n",
    " ''' Creating a Dictionary counts of features for each fold and each label'''\n",
    " List_of_all_features_count_for_sense1 = list()\n",
    " List_of_all_features_count_for_sense2 = list()\n",
    " for i in range(len(List_of_all_feature_count_for_sense1)):\n",
    " Dict_of_counts_in_each_train_set_for_sense1 = dict()\n",
    " for j in range(len(List_of_all_feature_count_for_sense1[i])):\n",
    " word = re.sub(r'[^-\\w]', '', List_of_all_feature_count_for_sense1[i][j])\n",
    " if word in Dict_of_counts_in_each_train_set_for_sense1.keys():\n",
    " Dict_of_counts_in_each_train_set_for_sense1[word] =\n",
    "Dict_of_counts_in_each_train_set_for_sense1[word] + 1\n",
    " elif word not in Dict_of_counts_in_each_train_set_for_sense1.keys():\n",
    " Dict_of_counts_in_each_train_set_for_sense1[word] = 1\n",
    "\n",
    "List_of_all_features_count_for_sense1.append(Dict_of_counts_in_each_train_set_for_sense1)\n",
    " # print(List_of_all_features_count_for_sense1[0])\n",
    " for i in range(len(List_of_all_feature_count_for_sense2)):\n",
    " Dict_of_counts_in_each_train_set_for_sense2 = dict()\n",
    " for j in range(len(List_of_all_feature_count_for_sense2[i])):\n",
    " word = re.sub(r'[^\\w-]', '', List_of_all_feature_count_for_sense2[i][j])\n",
    " if word not in Dict_of_counts_in_each_train_set_for_sense2.keys():\n",
    " Dict_of_counts_in_each_train_set_for_sense2[word] = 1\n",
    " elif word in Dict_of_counts_in_each_train_set_for_sense2.keys():\n",
    " Dict_of_counts_in_each_train_set_for_sense2[word] =\n",
    "Dict_of_counts_in_each_train_set_for_sense2[word] + 1\n",
    "\n",
    "List_of_all_features_count_for_sense2.append(Dict_of_counts_in_each_train_set_for_sense2)\n",
    " # print(List_of_all_features_count_for_sense2[0])\n",
    " '''Calculating the number of sense instances in each train set'''\n",
    " Sense1_Instances = []\n",
    " Sense2_Instances = []\n",
    " for i in range(len(list_of_train_sets)):\n",
    " sense_count_dict = dict()\n",
    " for j in range(len(list_of_train_sets[i])):\n",
    " for k in range(len(list_of_train_sets[i][j])):\n",
    " list_to_be_parsed = list_of_train_sets[i][j][k][0]\n",
    " sense = list_to_be_parsed[-1].split('=\"')[-1].split('%')[-1].strip('\"/>')\n",
    " if sense not in sense_count_dict.keys():\n",
    " sense_count_dict[sense] = 1\n",
    " elif sense in sense_count_dict.keys():\n",
    " sense_count_dict[sense] = sense_count_dict[sense] + 1\n",
    " Sense1_Instances.append(sense_count_dict['factory'])\n",
    " Sense2_Instances.append(sense_count_dict['living'])\n",
    " # Sense1_Instances.append(sense_count_dict['fish'])\n",
    " # Sense2_Instances.append(sense_count_dict['music'])\n",
    " # Sense1_Instances.append(sense_count_dict['machine'])\n",
    " # Sense2_Instances.append(sense_count_dict['bird'])\n",
    " # Sense1_Instances.append(sense_count_dict['physical'])\n",
    " # Sense2_Instances.append(sense_count_dict['legal'])\n",
    " # Sense1_Instances.append(sense_count_dict['hand'])\n",
    " # Sense2_Instances.append(sense_count_dict['tree'])\n",
    " # Sense1_Instances.append(sense_count_dict['container'])\n",
    " # Sense2_Instances.append(sense_count_dict['vehicle'])\n",
    " # print('Sense :', Sense1_Instances)\n",
    " ''' Dictionary of all the values for each feature and each sense'''\n",
    " Word_Sense1_Prob_Dict = dict()\n",
    " Word_Sense2_Prob_Dict = dict()\n",
    " for i in range(len(List_of_all_features_count_for_sense1)):\n",
    " for key in List_of_all_features_count_for_sense1[i].keys():\n",
    " Word_Sense1_Prob_Dict[key] = List_of_all_features_count_for_sense1[i][key] /\n",
    "Sense1_Instances[i]\n",
    " for i in range(len(List_of_all_features_count_for_sense2)):\n",
    " for key in List_of_all_features_count_for_sense2[i].keys():\n",
    " Word_Sense2_Prob_Dict[key] = List_of_all_features_count_for_sense2[i][key] /\n",
    "Sense2_Instances[i]\n",
    " '''Modifying the Dictionaries created above for words not present with certain label'''\n",
    " for i in range(len(list_of_train_sets)):\n",
    " ss = Sense1_Instances[i]\n",
    " ss2 = Sense2_Instances[i]\n",
    " for word in list_of_features.keys():\n",
    " if word not in Word_Sense2_Prob_Dict.keys():\n",
    " Word_Sense2_Prob_Dict[word] = (list_of_features[word] + 1) / (ss2 +\n",
    "unique_sense2_word_count[i])\n",
    " if word not in Word_Sense1_Prob_Dict.keys():\n",
    " Word_Sense1_Prob_Dict[word] = (list_of_features[word] + 1) / (ss +\n",
    "unique_sense1_word_count[i])\n",
    " return Word_Sense1_Prob_Dict, Word_Sense2_Prob_Dict\n",
    "def Test_Prob_Computation(Word_Sense1_Prob_Dict, Word_Sense2_Prob_Dict,\n",
    "list_of_test_sets, Prob_Sense_Dict):\n",
    " Instance = []\n",
    " Original_Sense = []\n",
    " for i in range(len(list_of_test_sets)):\n",
    " list_of_Instances_for_each_fold = []\n",
    " list_of_Original_Sense_for_each_fold = []\n",
    " for j in range(len(list_of_test_sets[i])):\n",
    " item = list_of_test_sets[i][j][0]\n",
    " list_of_Instances_for_each_fold.append(item[1].split('=\"')[-1].strip('\"'))\n",
    " list_of_Original_Sense_for_each_fold.append(item[2].split('=\"')[-1].strip('\"/>'))\n",
    " Instance.append(list_of_Instances_for_each_fold)\n",
    " Original_Sense.append(list_of_Original_Sense_for_each_fold)\n",
    " Calculated_Sense = dict()\n",
    " llist = []\n",
    " for i in range(len(list_of_test_sets)):\n",
    " list_of_actual_answers = []\n",
    " for j in range(len(list_of_test_sets[i])):\n",
    " overall_prob_for_sense1 = 0\n",
    " overall_prob_for_sense2 = 0\n",
    " Instance = list_of_test_sets[i][j][0][1].split('=\"')[-1].strip('\"')\n",
    " Actual_Sense = list_of_test_sets[i][j][0][2].split('=\"')[-1].split('%')[-1].strip('\"/>')\n",
    " Dict = dict()\n",
    " for k in range(len(list_of_test_sets[i][j][1])):\n",
    " word = re.sub(r'[^-\\w]', '', list_of_test_sets[i][j][1][k])\n",
    " # print(word, overall_prob_for_sense1, i, j, k)\n",
    " overall_prob_for_sense1 += numpy.log2(Word_Sense1_Prob_Dict[word])\n",
    " overall_prob_for_sense1 = overall_prob_for_sense1 * Prob_sense_Dict['factory']\n",
    " # overall_prob_for_sense1 = overall_prob_for_sense1 * Prob_sense_Dict['fish']\n",
    " # overall_prob_for_sense1 = overall_prob_for_sense1 * Prob_sense_Dict['machine']\n",
    " # overall_prob_for_sense1 = overall_prob_for_sense1 * Prob_sense_Dict['physical']\n",
    " # overall_prob_for_sense1 = overall_prob_for_sense1 * Prob_sense_Dict['hand']\n",
    " # overall_prob_for_sense1 = overall_prob_for_sense1 * Prob_sense_Dict['container']\n",
    " Dict['factory'] = overall_prob_for_sense1\n",
    " # Dict['fish'] = overall_prob_for_sense1\n",
    " # Dict['machine'] = overall_prob_for_sense1\n",
    " # Dict['physical'] = overall_prob_for_sense1\n",
    " # Dict['hand'] = overall_prob_for_sense1\n",
    " # Dict['container'] = overall_prob_for_sense1\n",
    " # print(overall_prob_for_sense1)\n",
    " for k in range(len(list_of_test_sets[i][j][1])):\n",
    " word = re.sub(r'[^-\\w]', '', list_of_test_sets[i][j][1][k])\n",
    " overall_prob_for_sense2 += numpy.log2(Word_Sense2_Prob_Dict[word])\n",
    " overall_prob_for_sense2 = overall_prob_for_sense2 * Prob_sense_Dict['living']\n",
    " # overall_prob_for_sense2 = overall_prob_for_sense2 * Prob_sense_Dict['music']\n",
    " # overall_prob_for_sense2 = overall_prob_for_sense1 * Prob_sense_Dict['bird']\n",
    " # overall_prob_for_sense2 = overall_prob_for_sense2 * Prob_sense_Dict['legal']\n",
    " # overall_prob_for_sense2 = overall_prob_for_sense2 * Prob_sense_Dict['tree']\n",
    " # overall_prob_for_sense2 = overall_prob_for_sense2 * Prob_sense_Dict['vehicle']\n",
    " Dict['living'] = overall_prob_for_sense2\n",
    " # Dict['music'] = overall_prob_for_sense2\n",
    " # Dict['bird'] = overall_prob_for_sense2\n",
    " # Dict['tree'] = overall_prob_for_sense2\n",
    " # Dict['legal'] = overall_prob_for_sense2\n",
    " # Dict['vehicle'] = overall_prob_for_sense2\n",
    " # print(Dict, max(Dict, key=Dict.get))\n",
    " Calculated_Sense[Instance] = max(Dict, key=Dict.get)\n",
    " list_of_actual_answers.append(max(Dict, key=Dict.get))\n",
    " llist.append(list_of_actual_answers)\n",
    " correct_response = 0\n",
    " total_count = 0\n",
    " list_to_be_used_in_dataframe = []\n",
    " for i in range(len(llist)):\n",
    " list_to_be_used_in_dataframe += [[\"Fold {}\".format(i+1)] + [' ']]\n",
    " correct_response1 = 0\n",
    " total_count1 = 0\n",
    " for j in range(len(llist[i])):\n",
    " if llist[i][j] == Original_Sense[i][j].split('%')[-1]:\n",
    " correct_response += 1\n",
    " correct_response1 += 1\n",
    " total_count += 1\n",
    " total_count1 += 1\n",
    " list_to_be_used_in_dataframe += [[list_of_test_sets[i][j][0][1].split('=\"')[-1].strip('\"')] +\n",
    "['plant%'+Calculated_Sense[list_of_test_sets[i][j][0][1].split('=\"')[-1].strip('\"')]]]\n",
    " else:\n",
    " list_to_be_used_in_dataframe += [[list_of_test_sets[i][j][0][1].split('=\"')[-1].strip('\"')] +\n",
    "['plant%'+Calculated_Sense[list_of_test_sets[i][j][0][1].split('=\"')[-1].strip('\"')]]]\n",
    " total_count += 1\n",
    " total_count1 += 1\n",
    " print('Accuracy for Fold{} is {}%'.format(i, round(100*(correct_response1/total_count1),\n",
    "2)))\n",
    " print('Overall Accuracy is {}%'.format(round(100*(correct_response / total_count), 2)))\n",
    " \n",
    "if __name__ == '__main__':\n",
    " input = sys.argv[1]\n",
    " a, b = data_process(input)\n",
    " c, lenS1_S2, lenS1, lenS2, Initial_label_dict, Prob_sense_Dict = data_segment(a)\n",
    " f1, f2, f3, f4, f5 = cross_fold_creation(c)\n",
    " train_features, test, fold_list = creating_train_test_segments(f1, f2, f3, f4, f5)\n",
    " Word_Sense_Prob1, Word_Sense_Prob2 =\n",
    "calculating_features_probabilities_for_each_set(train_features, lenS1_S2, lenS1, lenS2,\n",
    "Initial_label_dict, Prob_sense_Dict)\n",
    " Test_Prob_Computation(Word_Sense_Prob1, Word_Sense_Prob2, test, Prob_sense_Dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
